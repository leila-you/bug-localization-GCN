{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "\n",
    "import os \n",
    "import os.path  \n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'buggy' created\n",
      "Directory 'fixed' created\n"
     ]
    }
   ],
   "source": [
    "#D:/mythesis/Session-6/dataset1/lowdataset/\n",
    "#D:/dataset-json/hoppity_cg/partt/\n",
    "#D:/mythesis/Session-6/datasetbuglocalization/part\n",
    "#1  D:/mythesis/Session-6/dataset4/train2\n",
    "jsonfiles = [f for f in listdir('D:/mythesis/Session-6/dataset4/train2/') if isfile(join('D:/mythesis/Session-6/dataset4/train2/', f))]  \n",
    "directory = \"buggy\"\n",
    "directory2 = \"fixed\"\n",
    "parent_dir = \"D:/mythesis/Session-6/dataset4/dataset3\"  \n",
    "path_train = os.path.join(parent_dir, directory)\n",
    "os.mkdir(path_train) \n",
    "print(\"Directory '% s' created\" % directory) \n",
    "path_test = os.path.join(parent_dir, directory2) \n",
    "os.mkdir(path_test) \n",
    "print(\"Directory '% s' created\" % directory2) \n",
    "#D:/dataset-json/hoppity_cg/partn2/part/\n",
    "dir_src = (\"D:/mythesis/Session-6/dataset4/train2/\")\n",
    "dir_dst = (path_train)\n",
    "dir_dst2 = (path_test)\n",
    "\n",
    "for filename in os.listdir(dir_src):\n",
    "    #print(filename)\n",
    "    MyString2=filename\n",
    "    MyString1=\"_buggy\"\n",
    "    MyString3=\"_fixed\"\n",
    "    if filename.endswith(\".json\") and MyString2.find(MyString1) != -1 :\n",
    "        shutil.copy( dir_src + filename, dir_dst)\n",
    "    elif filename.endswith(\".json\") and MyString2.find(MyString3) != -1 :\n",
    "        shutil.copy( dir_src + filename, dir_dst2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leila\n"
     ]
    }
   ],
   "source": [
    "pathcurr=os.getcwd()\n",
    "print(pathcurr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def search_string_in_file(file_name, string_to_search):\n",
    "    \"\"\"Search for the given string in file and return lines containing that string,\n",
    "    along with line numbers\"\"\"\n",
    "    line_number = 0\n",
    "    list_of_results = []\n",
    "    with open(file_name, 'r') as read_obj:\n",
    "        for line in read_obj:\n",
    "            line_number += 1\n",
    "            if string_to_search in line:\n",
    "                list_of_results.append((line_number, line.rstrip()))\n",
    "    return list_of_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "list1=list()\n",
    "list1=[\n",
    "    \"Program\",\"Module\", \"Script\", \"Statement\", \"IterationStatement\", \"DoWhileStatement\", \"ForInStatement\", \"ForOfStatement\", \n",
    "    \"ForAwaitStatement\", \"ForStatement\", \"WhileStatement\", \"ClassDeclaration\", \"BlockStatement\", \"BreakStatement\", \n",
    "    \"ContinueStatement\", \"DebuggerStatement\", \"EmptyStatement\", \"ExpressionStatement\", \"IfStatement\", \"LabeledStatement\", \n",
    "    \"ReturnStatement\", \"SwitchStatement\", \"SwitchStatementWithDefault\", \"ThrowStatement\", \"TryCatchStatement\", \"TryFinallyStatement\", \n",
    "    \"VariableDeclarationStatement\", \"WithStatement\", \"FunctionDeclaration\", \"Expression\", \"MemberExpression\", \"ComputedMemberExpression\", \n",
    "    \"StaticMemberExpression\", \"ClassExpression\", \"LiteralBooleanExpression\", \"LiteralInfinityExpression\", \"LiteralNullExpression\", \n",
    "    \"LiteralNumericExpression\", \"LiteralRegExpExpression\", \"LiteralStringExpression\", \"ArrayExpression\", \"ArrowExpression\", \n",
    "    \"AssignmentExpression\", \"BinaryExpression\", \"CallExpression\", \"CompoundAssignmentExpression\", \"ConditionalExpression\", \n",
    "    \"FunctionExpression\", \"IdentifierExpression\", \"NewExpression\", \"NewTargetExpression\", \"ObjectExpression\", \"UnaryExpression\", \n",
    "    \"TemplateExpression\", \"ThisExpression\", \"UpdateExpression\", \"YieldExpression\", \"YieldGeneratorExpression\", \"AwaitExpression\", \n",
    "    \"PropertyName\", \"ComputedPropertyName\", \"StaticPropertyName\", \"ObjectProperty\", \"NamedObjectProperty\", \"MethodDefinition\", \n",
    "    \"Method\", \"Getter\", \"Setter\", \"DataProperty\", \"ShorthandProperty\", \"SpreadProperty\", \"ImportDeclaration\", \"Import\", \n",
    "    \"ImportNamespace\", \"ExportDeclaration\", \"ExportAllFrom\", \"ExportFrom\", \"ExportLocals\", \"Export\", \n",
    "    \"ExportDefault\", \"VariableReference\", \"BindingIdentifier\", \"AssignmentTargetIdentifier\", \"IdentifierExpression\", \n",
    "    \"BindingWithDefault\", \"MemberAssignmentTarget\", \"ComputedMemberAssignmentTarget\", \"StaticMemberAssignmentTarget\", \n",
    "    \"ArrayBinding\", \"ObjectBinding\", \"BindingProperty\", \"BindingPropertyIdentifier\", \"BindingPropertyProperty\", \n",
    "    \"AssignmentTargetWithDefault\", \"ArrayAssignmentTarget\", \"ObjectAssignmentTarget\", \"AssignmentTargetProperty\", \n",
    "    \"AssignmentTargetPropertyIdentifier\", \"AssignmentTargetPropertyProperty\", \"ClassElement\", \"ImportSpecifier\", \n",
    "    \"ExportFromSpecifier\", \"ExportLocalSpecifier\", \"Block\", \"CatchClause\", \"Directive\", \"FormalParameters\", \n",
    "    \"FunctionBody\", \"SpreadElement\", \"Super\", \"SwitchCase\", \"SwitchDefault\", \"TemplateElement\", \"VariableDeclaration\", \n",
    "    \"VariableDeclarator\",\"directives\",\"items\"\n",
    "]\n",
    "x=list1.index('VariableDeclaration')\n",
    "print(x)\n",
    "print(len(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultyoutube-dl_4_jsinterp.json\n",
      "youtube-dl_4_jsinterp\n",
      "update\n",
      "Total Matched lines :  2\n",
      "insert-tree\n",
      "Total Matched lines :  1112\n",
      "delete-tree\n",
      "Total Matched lines :  896\n",
      "delete\n",
      "Total Matched lines :  1938\n",
      "Mysssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "Mysssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#files1 = [f1 for f1 in listdir('D:/dataset-json/hoppity_cg/partn2/part/') if isfile(join('D:/dataset-json/hoppity_cg/partn2/part/', f1))]  \n",
    "\n",
    "path_train1 = \"C:/Users/Leila/datasetpy/buggy/\"\n",
    "pathcurr=os.getcwd()\n",
    "\n",
    "for file1 in listdir('C:/Users/Leila/datasetpy/buggy/'):\n",
    "    #print(file1)\n",
    "    txt=file1\n",
    "    #print(txt)\n",
    "    txt2=\"result\"+txt\n",
    "    print(txt2)\n",
    "    tf4='C:/Users/Leila/datasetpy/buggy/'+file1\n",
    "#     tf5=pathcurr+\"/result2\"\n",
    "    for file2 in listdir(\"C:/Users/Leila/datasetpy/result\"):\n",
    "        \n",
    "        tf=file2\n",
    "        #print(tf)\n",
    "        tf2=tf.split(\".txt\")\n",
    "        tfname=tf2[0]\n",
    "        print(tfname)\n",
    "        #if(txt2==tfname):\n",
    "        if(True):\n",
    "            sample='C:/Users/Leila/datasetpy/result/'+tf\n",
    "            lupdate=list()\n",
    "            matched_lines = search_string_in_file(sample, 'update-node')\n",
    "            print(\"update\")\n",
    "            print('Total Matched lines : ', len(matched_lines))\n",
    "            for elem in matched_lines:                \n",
    "                #print('Line Number = ', elem[0], ' :: Line = ', elem[1])\n",
    "                e=elem[0]+1\n",
    "                e2=elem[0]+2\n",
    "                line = open(sample, \"r\").readlines()[e]\n",
    "#                 print(line)\n",
    "                re = line.rfind('[')\n",
    "                re2 = line.rfind(']')\n",
    "                re3 = line.rfind(',',re,re2)\n",
    "                re4=re+1\n",
    "                re5=re3+1\n",
    "                ind=line[re4:re3]\n",
    "                ind2=line[re5:re2]\n",
    "                line2 = open(sample, \"r\").readlines()[e2]\n",
    "                f = open('C:/Users/Leila/datasetpy/buggy/'+file1, 'r')\n",
    "                f.seek(int(ind)+1)\n",
    "                inde=int(ind2)\n",
    "                inde2=int(ind)\n",
    "                ind3=inde-inde2-2\n",
    "                strjsonread=f.read(ind3)\n",
    "                text_as_string1 = open('C:/Users/Leila/datasetpy/buggy/'+file1, 'r').read()\n",
    "#                 result = text_as_string.index('nodes')\n",
    "# #                 print(result)\n",
    "#                 result2 = text_as_string.index('edges')\n",
    "#                 print(result2)\n",
    "#                 if int(indinsertt4)< result2 and int(indinsertt24)<result2:\n",
    "                re54 = text_as_string1.find('[',int(inde),)\n",
    "                re64 = text_as_string1.find(',',re54,)\n",
    "#                     print(re66)\n",
    "#                     print(re55)\n",
    "                klm1=text_as_string1[re54+1:re64]\n",
    "                klm2=[int(s) for s in klm1.split() if s.isdigit()]\n",
    "#                 print(type(klm2))\n",
    "                if len(klm2)>0:\n",
    "                    \n",
    "                    klm3=int(klm2[0])\n",
    "                \n",
    "                    lupdate.append(klm3-1)\n",
    "#                 with open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1) as train_f:\n",
    "#                     dict_t1 = json.load(train_f)\n",
    "#                     array=dict_t1[\"nodes\"]\n",
    "#                     for a in array:\n",
    "                        \n",
    "#                         if(a[0]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "#                         elif(a[1]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "#                         elif(a[2]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "            linserttree=list()\n",
    "            \n",
    "            matched_lines8 = search_string_in_file(sample, 'insert-tree')\n",
    "#             matched_lines4 = search_string_in_file(tf4, 'edges')\n",
    "            print('insert-tree')\n",
    "            print('Total Matched lines : ', len(matched_lines8))\n",
    "            \n",
    "            for elem7 in matched_lines8:             \n",
    "    \n",
    "                dinserttree4=False\n",
    "                #print('Line Number = ', elem1[0], ' :: Line = ', elem1[1])                \n",
    "                linserttree4=list()\n",
    "                einserttree4=elem7[0]+2\n",
    "                einserttree24=elem7[0]+4\n",
    "#                 einsert3=elem4[0]+3\n",
    "                lineinserttree4 = open(sample, \"r\").readlines()[einserttree4]\n",
    "#                 print(lineinserttree4)\n",
    "                if 'String' not in lineinserttree4:\n",
    "                    continue\n",
    "                einsertt4=elem7[0]+4\n",
    "                einsertt24=elem7[0]+6\n",
    "#                 finsert4= open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1, 'r')\n",
    "                lineinsertt4 = open(sample, \"r\").readlines()[einsertt4]\n",
    "                reinsertt4 = lineinsertt4.rfind('[')\n",
    "                reinsertt24 = lineinsertt4.rfind(']')\n",
    "                reinsertt34 = lineinsertt4.rfind(',',reinsertt4,reinsertt24)\n",
    "                reinsertt44=reinsertt4+1\n",
    "                reinsertt54=reinsertt34+1\n",
    "                indinsertt4=lineinsertt4[reinsertt44:reinsertt34]\n",
    "                indinsertt24=lineinsertt4[reinsertt54:reinsertt24]\n",
    "#                 print(indinsertt4)\n",
    "#                 print(indinsertt24)\n",
    "#                 lineinsert24 = open(sample, \"r\").readlines()[einsert24]\n",
    "#                 reinsertat = lineinsert24.rfind('at ')\n",
    "#                 lininsertsibl=lineinsert24[reinsertat+3:]\n",
    "#                 lininsertsibl=int(lininsertsibl)\n",
    "#                 print(lininsertsibl)\n",
    "#                 finsertt4= open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1, 'r')\n",
    "                text_as_string = open('C:/Users/Leila/datasetpy/buggy/'+file1, 'r').read()\n",
    "                result = text_as_string.index('nodes')\n",
    "#                 print(result)\n",
    "                result2 = text_as_string.index('edges')\n",
    "#                 print(result2)\n",
    "                if int(indinsertt4)< result2 and int(indinsertt24)<result2:\n",
    "                    re55 = text_as_string.find('[',int(indinsertt4),)\n",
    "                    re66 = text_as_string.find(',',re55,)\n",
    "#                     print(re66)\n",
    "#                     print(re55)\n",
    "                    klm=text_as_string[re55+1:re66]\n",
    "                    klmm2=[int(s) for s in klm.split() if s.isdigit()]\n",
    "#                 print(type(klm2))\n",
    "                    if len(klmm2)>0:\n",
    "                    \n",
    "                        klmm3=int(klmm2[0])\n",
    "                \n",
    "#                     lupdate.append(klm3-1)\n",
    "#                     klm=int(klm)\n",
    "#                     print(klm)\n",
    "                        linserttree.append(klmm3-2)\n",
    "#                     print(\"OOOOOOOOOOOOOOOOKKKKKKKKKKKKKKKKKKKKKK\")\n",
    "                \n",
    "#                 matched_lines10 = search_string_in_file(finsertt4, 'nodes')\n",
    "#                 rt4 = finsertt4.rfind('edges')\n",
    "#                 print(\":::::::::::::::::::::::::\")\n",
    "\n",
    "            ldelete5=list()\n",
    "            matched_lines5 = search_string_in_file(sample, 'delete-tree')\n",
    "            print('delete-tree')\n",
    "            print('Total Matched lines : ', len(matched_lines5))\n",
    "            for elem5 in matched_lines5: \n",
    "                d5=False\n",
    "                #print('Line Number = ', elem5[0], ' :: Line = ', elem5[1])                \n",
    "                l5=list()\n",
    "                e5=elem5[0]+1\n",
    "                e25=elem5[0]+2\n",
    "                line5 = open(sample, \"r\").readlines()[e5]\n",
    "                re5 = line5.rfind('[')\n",
    "                re25 = line5.rfind(']')\n",
    "                re35 = line5.rfind(',',re5,re25)\n",
    "                re45=re5+1\n",
    "                re55=re35+1\n",
    "                ind5=line5[re45:re35]\n",
    "#                 print(ind5)\n",
    "                ind25=line5[re55:re25]\n",
    "#                 print(ind25)\n",
    "                line25 = open(sample, \"r\").readlines()[e25]\n",
    "                f5 = open('C:/Users/Leila/datasetpy/buggy/'+file1, 'r')\n",
    "                f5.seek(int(ind5))\n",
    "                inde5=int(ind25)\n",
    "                inde25=int(ind5)\n",
    "                ind35=inde5-inde25\n",
    "                strjsonread5=f5.read(ind35)\n",
    "#                 print(strjsonread5)\n",
    "                if '[' in strjsonread5:\n",
    "#                     print(\"LLLLLLLLL\")\n",
    "                    sl5=len(strjsonread5)\n",
    "                    s15=strjsonread5.find(', ')\n",
    "                    s25=strjsonread5[1:s15]\n",
    "#                     print(s25)\n",
    "                    l5.append(s25)\n",
    "                    s35=strjsonread5.rfind(', ')\n",
    "                    s45=strjsonread5[s15+3:s35-1]\n",
    "#                     print(s45)\n",
    "                    l5.append(s45)          \n",
    "                    s65=strjsonread5[s35+3:sl5-2]\n",
    "                    l5.append(s65)\n",
    "#                     print(l5)\n",
    "                    with open('C:/Users/Leila/datasetpy/buggy/'+file1) as train_f5:\n",
    "                        dict_t15 = json.load(train_f5)\n",
    "                        array25=dict_t15[\"edges\"]\n",
    "                        for aw5 in array25:\n",
    "                        \n",
    "                            if aw5==l5:\n",
    "                                d5=True\n",
    "                        if d5==False:\n",
    "#                             print(\"FFFFFFFFFFFFFFFFFF\")\n",
    "                            array5=dict_t15[\"nodes\"]\n",
    "                            for a5 in array5:\n",
    "                                a5[0]=str(a5[0])\n",
    "#                                 print(\"KKKKKKKKKKOOOO\")\n",
    "                                if(a5==l5):\n",
    "#                                     print(\"truuuuuuuuuuuuuuuuuuuuuuuuuuuue\")\n",
    "                                    ldelete5.append(int(a5[0]))    \n",
    "            ldelete=list()\n",
    "            matched_lines1 = search_string_in_file(sample, 'delete-node')\n",
    "            print('delete')\n",
    "            print('Total Matched lines : ', len(matched_lines1))\n",
    "            for elem1 in matched_lines1: \n",
    "                d=False\n",
    "                #print('Line Number = ', elem1[0], ' :: Line = ', elem1[1])                \n",
    "                l=list()\n",
    "                e=elem1[0]+1\n",
    "                e2=elem1[0]+2\n",
    "                line = open(sample, \"r\").readlines()[e]\n",
    "                re = line.rfind('[')\n",
    "                re2 = line.rfind(']')\n",
    "                re3 = line.rfind(',',re,re2)\n",
    "                re4=re+1\n",
    "                re5=re3+1\n",
    "                ind=line[re4:re3]\n",
    "                ind2=line[re5:re2]\n",
    "                line2 = open(sample, \"r\").readlines()[e2]\n",
    "                f = open('C:/Users/Leila/datasetpy/buggy/'+file1, 'r')\n",
    "                f.seek(int(ind))\n",
    "                inde=int(ind2)\n",
    "                inde2=int(ind)\n",
    "                ind3=inde-inde2\n",
    "                strjsonread=f.read(ind3)\n",
    "                \n",
    "                sl=len(strjsonread)\n",
    "                s1=strjsonread.find(', ')\n",
    "                s2=strjsonread[1:s1]\n",
    "                l.append(s2)\n",
    "                s3=strjsonread.rfind(', ')\n",
    "                s4=strjsonread[s1+3:s3-1]\n",
    "                l.append(s4)          \n",
    "                s6=strjsonread[s3+3:sl-2]\n",
    "                l.append(s6)\n",
    "                with open('C:/Users/Leila/datasetpy/buggy/'+file1) as train_f:\n",
    "                    dict_t1 = json.load(train_f)\n",
    "                    array2=dict_t1[\"edges\"]\n",
    "                    for aw in array2:\n",
    "                        \n",
    "                        if aw==l:\n",
    "                            d=True\n",
    "                    if d==False:\n",
    "                        array=dict_t1[\"nodes\"]\n",
    "                        for a in array:\n",
    "                            a[0]=str(a[0])\n",
    "                            if(a==l):\n",
    "#                                 print(\"truuuuuuuuuuuuuuuuuuuuuuuuuuuue\")\n",
    "                                ldelete.append(int(a[0]))\n",
    "#             print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "# #             print(len(ldelete5))\n",
    "            with open('C:/Users/Leila/datasetpy/buggy/'+file1) as train_f:\n",
    "                                      \n",
    "                dict_t1 = json.load(train_f)\n",
    "                array=dict_t1[\"nodes\"]\n",
    "\n",
    "                for item in array:\n",
    "\n",
    "                    if(len(lupdate)>0 and item[0] in lupdate):\n",
    "                        print(\"Mysssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\")\n",
    "                        item.append(\"update\")\n",
    "                    elif(item[0] in ldelete):\n",
    "                        item.append(\"delete\")\n",
    "                    elif(item[0] in ldelete5):\n",
    "                        item.append(\"delete-tree\")\n",
    "                    elif (item[0] in linserttree):\n",
    "                        item.append(\"insert-node\")\n",
    "                    else:\n",
    "                        item.append(\"bug-free\")                 \n",
    "                        ## Save our changes to JSON file\n",
    "                jsonFile = open('C:/Users/Leila/datasetpy/buggy/'+file1, \"w+\")\n",
    "                jsonFile.write(json.dumps(dict_t1))\n",
    "                jsonFile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#files1 = [f1 for f1 in listdir('D:/dataset-json/hoppity_cg/partn2/part/') if isfile(join('D:/dataset-json/hoppity_cg/partn2/part/', f1))]  \n",
    "\n",
    "path_train1 = \"/dataset3/buggy/\"\n",
    "pathcurr=os.getcwd()\n",
    "\n",
    "for file1 in listdir('/dataset3/buggy/'):\n",
    "    print(file1)\n",
    "    txt=file1\n",
    "    #print(txt)\n",
    "    txt2=\"result\"+txt\n",
    "    tf4='/dataset3/buggy/'+file1\n",
    "#     tf5=pathcurr+\"/result2\"\n",
    "    for file2 in listdir(\"/result2\"):\n",
    "        \n",
    "        tf=file2\n",
    "        tf2=tf.split(\".txt\")\n",
    "        tfname=tf2[0]\n",
    "        if(txt2==tfname):\n",
    "            sample='/result2/'+tf\n",
    "            lupdate=list()\n",
    "            matched_lines = search_string_in_file(sample, 'update-node')\n",
    "            print(\"update\")\n",
    "            print('Total Matched lines : ', len(matched_lines))\n",
    "            for elem in matched_lines:                \n",
    "                #print('Line Number = ', elem[0], ' :: Line = ', elem[1])\n",
    "                e=elem[0]+1\n",
    "                e2=elem[0]+2\n",
    "                line = open(sample, \"r\").readlines()[e]\n",
    "#                 print(line)\n",
    "                re = line.rfind('[')\n",
    "                re2 = line.rfind(']')\n",
    "                re3 = line.rfind(',',re,re2)\n",
    "                re4=re+1\n",
    "                re5=re3+1\n",
    "                ind=line[re4:re3]\n",
    "                ind2=line[re5:re2]\n",
    "                line2 = open(sample, \"r\").readlines()[e2]\n",
    "                f = open('/dataset3/buggy/'+file1, 'r')\n",
    "                f.seek(int(ind)+1)\n",
    "                inde=int(ind2)\n",
    "                inde2=int(ind)\n",
    "                ind3=inde-inde2-2\n",
    "                strjsonread=f.read(ind3)\n",
    "                text_as_string1 = open('/dataset3/buggy/'+file1, 'r').read()\n",
    "#                 result = text_as_string.index('nodes')\n",
    "# #                 print(result)\n",
    "#                 result2 = text_as_string.index('edges')\n",
    "#                 print(result2)\n",
    "#                 if int(indinsertt4)< result2 and int(indinsertt24)<result2:\n",
    "                re54 = text_as_string1.find('[',int(inde),)\n",
    "                re64 = text_as_string1.find(',',re54,)\n",
    "#                     print(re66)\n",
    "#                     print(re55)\n",
    "                klm1=text_as_string1[re54+1:re64]\n",
    "                klm2=[int(s) for s in klm1.split() if s.isdigit()]\n",
    "#                 print(type(klm2))\n",
    "                if len(klm2)>0:\n",
    "                    \n",
    "                    klm3=int(klm2[0])\n",
    "                \n",
    "                    lupdate.append(klm3-1)\n",
    "#                 with open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1) as train_f:\n",
    "#                     dict_t1 = json.load(train_f)\n",
    "#                     array=dict_t1[\"nodes\"]\n",
    "#                     for a in array:\n",
    "                        \n",
    "#                         if(a[0]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "#                         elif(a[1]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "#                         elif(a[2]==strjsonread):\n",
    "#                             lupdate.append(a[0])\n",
    "            linserttree=list()\n",
    "            \n",
    "            matched_lines8 = search_string_in_file(sample, 'insert-tree')\n",
    "#             matched_lines4 = search_string_in_file(tf4, 'edges')\n",
    "            print('insert-tree')\n",
    "            print('Total Matched lines : ', len(matched_lines8))\n",
    "            \n",
    "            for elem7 in matched_lines8:             \n",
    "    \n",
    "                dinserttree4=False\n",
    "                #print('Line Number = ', elem1[0], ' :: Line = ', elem1[1])                \n",
    "                linserttree4=list()\n",
    "                einserttree4=elem7[0]+2\n",
    "                einserttree24=elem7[0]+4\n",
    "#                 einsert3=elem4[0]+3\n",
    "                lineinserttree4 = open(sample, \"r\").readlines()[einserttree4]\n",
    "#                 print(lineinserttree4)\n",
    "                if 'String' not in lineinserttree4:\n",
    "                    continue\n",
    "                einsertt4=elem7[0]+4\n",
    "                einsertt24=elem7[0]+6\n",
    "#                 finsert4= open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1, 'r')\n",
    "                lineinsertt4 = open(sample, \"r\").readlines()[einsertt4]\n",
    "                reinsertt4 = lineinsertt4.rfind('[')\n",
    "                reinsertt24 = lineinsertt4.rfind(']')\n",
    "                reinsertt34 = lineinsertt4.rfind(',',reinsertt4,reinsertt24)\n",
    "                reinsertt44=reinsertt4+1\n",
    "                reinsertt54=reinsertt34+1\n",
    "                indinsertt4=lineinsertt4[reinsertt44:reinsertt34]\n",
    "                indinsertt24=lineinsertt4[reinsertt54:reinsertt24]\n",
    "#                 print(indinsertt4)\n",
    "#                 print(indinsertt24)\n",
    "#                 lineinsert24 = open(sample, \"r\").readlines()[einsert24]\n",
    "#                 reinsertat = lineinsert24.rfind('at ')\n",
    "#                 lininsertsibl=lineinsert24[reinsertat+3:]\n",
    "#                 lininsertsibl=int(lininsertsibl)\n",
    "#                 print(lininsertsibl)\n",
    "#                 finsertt4= open('D:/mythesis/Session-6/dataset4/train3/buggy/'+file1, 'r')\n",
    "                text_as_string = open('/dataset3/buggy/'+file1, 'r').read()\n",
    "                result = text_as_string.index('nodes')\n",
    "#                 print(result)\n",
    "                result2 = text_as_string.index('edges')\n",
    "#                 print(result2)\n",
    "                if int(indinsertt4)< result2 and int(indinsertt24)<result2:\n",
    "                    re55 = text_as_string.find('[',int(indinsertt4),)\n",
    "                    re66 = text_as_string.find(',',re55,)\n",
    "#                     print(re66)\n",
    "#                     print(re55)\n",
    "                    klm=text_as_string[re55+1:re66]\n",
    "                    klmm2=[int(s) for s in klm.split() if s.isdigit()]\n",
    "#                 print(type(klm2))\n",
    "                    if len(klmm2)>0:\n",
    "                    \n",
    "                        klmm3=int(klmm2[0])\n",
    "                \n",
    "#                     lupdate.append(klm3-1)\n",
    "#                     klm=int(klm)\n",
    "#                     print(klm)\n",
    "                        linserttree.append(klmm3-2)\n",
    "#                     print(\"OOOOOOOOOOOOOOOOKKKKKKKKKKKKKKKKKKKKKK\")\n",
    "                \n",
    "#                 matched_lines10 = search_string_in_file(finsertt4, 'nodes')\n",
    "#                 rt4 = finsertt4.rfind('edges')\n",
    "#                 print(\":::::::::::::::::::::::::\")\n",
    "\n",
    "            ldelete5=list()\n",
    "            matched_lines5 = search_string_in_file(sample, 'delete-tree')\n",
    "            print('delete-tree')\n",
    "            print('Total Matched lines : ', len(matched_lines5))\n",
    "            for elem5 in matched_lines5: \n",
    "                d5=False\n",
    "                #print('Line Number = ', elem5[0], ' :: Line = ', elem5[1])                \n",
    "                l5=list()\n",
    "                e5=elem5[0]+1\n",
    "                e25=elem5[0]+2\n",
    "                line5 = open(sample, \"r\").readlines()[e5]\n",
    "                re5 = line5.rfind('[')\n",
    "                re25 = line5.rfind(']')\n",
    "                re35 = line5.rfind(',',re5,re25)\n",
    "                re45=re5+1\n",
    "                re55=re35+1\n",
    "                ind5=line5[re45:re35]\n",
    "#                 print(ind5)\n",
    "                ind25=line5[re55:re25]\n",
    "#                 print(ind25)\n",
    "                line25 = open(sample, \"r\").readlines()[e25]\n",
    "                f5 = open('/dataset3/buggy/'+file1, 'r')\n",
    "                f5.seek(int(ind5))\n",
    "                inde5=int(ind25)\n",
    "                inde25=int(ind5)\n",
    "                ind35=inde5-inde25\n",
    "                strjsonread5=f5.read(ind35)\n",
    "#                 print(strjsonread5)\n",
    "                if '[' in strjsonread5:\n",
    "#                     print(\"LLLLLLLLL\")\n",
    "                    sl5=len(strjsonread5)\n",
    "                    s15=strjsonread5.find(', ')\n",
    "                    s25=strjsonread5[1:s15]\n",
    "#                     print(s25)\n",
    "                    l5.append(s25)\n",
    "                    s35=strjsonread5.rfind(', ')\n",
    "                    s45=strjsonread5[s15+3:s35-1]\n",
    "#                     print(s45)\n",
    "                    l5.append(s45)          \n",
    "                    s65=strjsonread5[s35+3:sl5-2]\n",
    "                    l5.append(s65)\n",
    "#                     print(l5)\n",
    "                    with open('/dataset3/buggy/'+file1) as train_f5:\n",
    "                        dict_t15 = json.load(train_f5)\n",
    "                        array25=dict_t15[\"edges\"]\n",
    "                        for aw5 in array25:\n",
    "                        \n",
    "                            if aw5==l5:\n",
    "                                d5=True\n",
    "                        if d5==False:\n",
    "#                             print(\"FFFFFFFFFFFFFFFFFF\")\n",
    "                            array5=dict_t15[\"nodes\"]\n",
    "                            for a5 in array5:\n",
    "                                a5[0]=str(a5[0])\n",
    "#                                 print(\"KKKKKKKKKKOOOO\")\n",
    "                                if(a5==l5):\n",
    "#                                     print(\"truuuuuuuuuuuuuuuuuuuuuuuuuuuue\")\n",
    "                                    ldelete5.append(int(a5[0]))    \n",
    "            ldelete=list()\n",
    "            matched_lines1 = search_string_in_file(sample, 'delete-node')\n",
    "            print('delete')\n",
    "            print('Total Matched lines : ', len(matched_lines1))\n",
    "            for elem1 in matched_lines1: \n",
    "                d=False\n",
    "                #print('Line Number = ', elem1[0], ' :: Line = ', elem1[1])                \n",
    "                l=list()\n",
    "                e=elem1[0]+1\n",
    "                e2=elem1[0]+2\n",
    "                line = open(sample, \"r\").readlines()[e]\n",
    "                re = line.rfind('[')\n",
    "                re2 = line.rfind(']')\n",
    "                re3 = line.rfind(',',re,re2)\n",
    "                re4=re+1\n",
    "                re5=re3+1\n",
    "                ind=line[re4:re3]\n",
    "                ind2=line[re5:re2]\n",
    "                line2 = open(sample, \"r\").readlines()[e2]\n",
    "                f = open('/dataset3/buggy/'+file1, 'r')\n",
    "                f.seek(int(ind))\n",
    "                inde=int(ind2)\n",
    "                inde2=int(ind)\n",
    "                ind3=inde-inde2\n",
    "                strjsonread=f.read(ind3)\n",
    "                \n",
    "                sl=len(strjsonread)\n",
    "                s1=strjsonread.find(', ')\n",
    "                s2=strjsonread[1:s1]\n",
    "                l.append(s2)\n",
    "                s3=strjsonread.rfind(', ')\n",
    "                s4=strjsonread[s1+3:s3-1]\n",
    "                l.append(s4)          \n",
    "                s6=strjsonread[s3+3:sl-2]\n",
    "                l.append(s6)\n",
    "                with open('/dataset3/buggy/'+file1) as train_f:\n",
    "                    dict_t1 = json.load(train_f)\n",
    "                    array2=dict_t1[\"edges\"]\n",
    "                    for aw in array2:\n",
    "                        \n",
    "                        if aw==l:\n",
    "                            d=True\n",
    "                    if d==False:\n",
    "                        array=dict_t1[\"nodes\"]\n",
    "                        for a in array:\n",
    "                            a[0]=str(a[0])\n",
    "                            if(a==l):\n",
    "#                                 print(\"truuuuuuuuuuuuuuuuuuuuuuuuuuuue\")\n",
    "                                ldelete.append(int(a[0]))\n",
    "#             print(\"hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\")\n",
    "# #             print(len(ldelete5))\n",
    "            with open('/dataset3/buggy/'+file1) as train_f:\n",
    "                                      \n",
    "                dict_t1 = json.load(train_f)\n",
    "                array=dict_t1[\"nodes\"]\n",
    "\n",
    "                for item in array:\n",
    "\n",
    "                    if(len(lupdate)>0 and item[0] in lupdate):\n",
    "                        print(\"Mysssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\")\n",
    "                        item.append(\"update\")\n",
    "                    elif(item[0] in ldelete):\n",
    "                        item.append(\"delete\")\n",
    "                    elif(item[0] in ldelete5):\n",
    "                        item.append(\"delete-tree\")\n",
    "                    elif (item[0] in linserttree):\n",
    "                        item.append(\"insert-node\")\n",
    "                    else:\n",
    "                        item.append(\"bug-free\")                 \n",
    "                        ## Save our changes to JSON file\n",
    "                jsonFile = open('/dataset3/buggy/'+file1, \"w+\")\n",
    "                jsonFile.write(json.dumps(dict_t1))\n",
    "                jsonFile.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
